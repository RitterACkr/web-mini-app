# Othello Learning AI

ブラウザ上でニューラルネットワークによる強化学習・可視化・成果物との対戦が可能なWebアプリケーションです.

---

## 概要
「AIの成長を観察・実感できる実験環境」をコンセプトに HTML / CSS / JavaScript (TensorFlow.js) のみで構成されたシングルページアプリです.

---

## 機能一覧

| **機能** | **内容** |
|----|----|
| 対戦学習 | メインモデル vs スナップショットモデルでの強化学習 |
| 学習パラメータ設定 | epoch数・学習率・ε-greedy・割引率・snapshot間隔をUI上で変更可能 |
| 勝率推移グラフ | 学習中の直近の勝率をグラフ化し,リアルタイムで更新 |
| AIとの対戦 | 学習済みAIと対戦 |
| NN 可視化 | 重みを青/赤, ノードの活性化を明暗でリアルタイムで表示 |
| 強さチェック | 学習済みAIをランダムAIと100戦させて勝率を測定 |

---

## ファイル構成

```
index.html  # UI構成
style.css   # スタイル
src/
    main.js # UI操作・学習コントロール・対戦ロジック・グラフ描画
    game.js # オセロゲームエンジン
    ai.js   # NNモデル・学習ループ・Experience Replayバッファ
    ui.js   # NN可視化
```

---

## 使い方

### 1. Training - 学習モード

1. ブラウザで `index.html` を開く
2. 学習パラメータを設定 (推奨値は下記参照)
3. **▶ 学習開始** を押すと自動的に学習開始
4. 進捗状況・盤面・勝率グラフ・NN可視化がリアルタイムで更新される

### 2. Battle - 対戦モード

1. 学習完了後に **Battle** タブを開く
2. プレイヤーの色 (黒/白) を選択
3. **▶ 対戦開始** を押してマスをクリックして手を打つ

### 3. View NN - NN可視化

1. **View NN** タブを開く
2. エッジの色 (青=正の重み / 赤=負の重み) とノードの明暗 (活性化) を確認
3. 学習中は10epochごとに自動更新される

### 4. 強さチェック

1. **View NN** タブ下部の **▶ 強さチェック開始** を押す
2. ランダムAIとの100戦が自動的に開始し勝率を測定

---

## 推奨学習パラメータ

| パラメータ | 推奨値 | 補足 |
|----|----|----|
| epoch数 | 5000 | 多いほど強くなる (目安20分～60分) |
| 学習率 (α) | 0.001 | デフォルトのまま |
| ε-greedy | 0.5 | 序盤は探索多め, 学習で下限値0.05まで自動減少 |
| 割引率 (γ) | 0.95 | デフォルトのまま |
| snapshot間隔 | epochが多い場合は長めに設定 |

---

## 技術構成

- **TensorFlow.js** : NNモデルの構築・学習・推論
- **Canvas API** : 盤面・グラフ・NN可視化の描画
- **強化アルゴリズム** : Monte Carlo + Experience Replay + スナップショット対戦
  - 勝ち +1 / 引き分け +0.1 / 負け -1 の報酬
  - ゲーム間の石差による途中報酬も加味
  - スナップショットによって対戦相手AIを更新

---

## NNアーキテクチャ

```
Input（192 dimensions）→ Hidden1（128, ReLU）→ Hidden2（64, ReLU）→ Output（64 dimensions, Linear）
```

入力は"自分の石(64) + 相手の石(64) + 打てる手(64)"の3チャンネル. 出力は盤面全マスのQ値

---

## 今後の展望

- [ ] 学習済みモデルの保存・読み込み
- [ ] 学習済みモデルに対しての追加学習を可能に
- [ ] ネットワークの深化 (隠れ層追加・ユニット数増加)
- [ ] 強さチェックの履歴グラフ

---

## v1.0.0

初回リリース. 最低限の機能と学習済AIの強さを実現